{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Lib"
      ],
      "metadata": {
        "id": "18FA3D4A9vWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "xTWlFiZRMojV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa28dca6-6a3a-4502-d397-0bb0df60e0d7"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.11.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.14.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "-Y_yHh9U3Ik5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def extract_arabic_text(text):\n",
        "    # Remove emojis and latin text\n",
        "    text = re.sub(r\"[^\\u0600-\\u06FF\\s]+\", \"\", text)\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    # Return the remaining Arabic text\n",
        "    return text.strip()\n",
        "\n",
        "# Example usage\n",
        "text = \"Hello ğŸ‘‹, Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…\"\n",
        "arabic_text = extract_arabic_text(text)\n",
        "print(arabic_text)  # Output: \"Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SN5Voy1I38Vh",
        "outputId": "5f12f9af-2fa3-49ad-9b08-35c0ee73f7f6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ù…Ø±Ø­Ø¨Ø§ Ø¨Ø§Ù„Ø¹Ø§Ù„Ù…\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "44hGsiAp95_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the training data\n",
        "with open(\"/content/drive/MyDrive/ads.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "GnB1CTctOq1p"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the training data\n",
        "with open(\"/content/drive/MyDrive/arabic_text.txt\", \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()"
      ],
      "metadata": {
        "id": "IsnJAFWl-aEH"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "databn = pd.read_csv(\"/content/drive/MyDrive/MTCD.csv\")"
      ],
      "metadata": {
        "id": "0VZxvC3729c0"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "j6KyVeIr-fA8",
        "outputId": "6270b1d9-2e5b-4d36-adab-da6ac7d6b210"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ufeffØ³Ù„Ø§Ù… Ù„Ø¨Ø§Ø³ ÙƒØ¯ÙŠØ± Ø¨Ø®ÙŠØ±\\nØ£Ø¬ÙŠ ØªØ´Ø±Ø¨ Ù‚Ù‡ÙˆØ©\\nØ³Ø± ØªÙ„Ø¹Ø¨'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOX-E1_33MrX",
        "outputId": "14b6965f-c9e0-4ba7-e2a6-347523747657"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30051"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "databn = pd.read_csv(\"/content/drive/MyDrive/MTCD.csv\")\n",
        "databn[\"text\"] = databn[\"text\"].apply(extract_arabic_text)\n",
        "databn = databn.drop(columns= \"labels\")"
      ],
      "metadata": {
        "id": "f4krJgzG4BSR"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the dataset\n",
        "dataa = pd.read_csv(\"/content/drive/MyDrive/ads.csv\", encoding=\"utf-8\")"
      ],
      "metadata": {
        "id": "h3KCjMgF_rYH"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = dataa[:30]"
      ],
      "metadata": {
        "id": "r4qyJd5cANOg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.head(20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "_rtsgkDsJVbE",
        "outputId": "11136592-f945-4de6-d928-3b1d12bac944"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                            ads_clean\n",
              "0   Ø­ØµØ±ÙŠØ§Ù‹ Ùˆ ØºÙŠØ± Ø¹Ù†Ø¯ Ø§ÙˆØ±Ù†Ø¬ØŒ Ø¹ÙŠØ´ Ù„ÙÙŠØ¨Ø± ÙØ¯Ø§Ø±Ùƒ ÙˆÙ†ØªØ§ Ù‡...\n",
              "1   ØªØ¹Ø±ÙÙˆØ§ Ù…Ø¹Ù†Ø§ Ø¹Ù„Ù‰ Ø³Ø± Ø§Ù„Ø­Ø±ÙØ© Ù…Ø¹ ÙØ§Ø·Ù…Ø©ØŒ Ø¹Ù…Ø±Ø§Ù† Ùˆ Ù‡Ø´...\n",
              "2   Ø¨ÙØ¶Ù„ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø¯ÙŠØ§Ù„ÙƒÙ… ÙˆØ²Ø¹Ù†Ø§ Ø§Ù„Ø§Ø£Ù†ØªØ±Ù†Øª Ø¹Ù„Ù‰ Ø¹Ø¯Ø© Ø¬Ù…...\n",
              "3   Ø§Ù„Ø³Ø§Ø¹Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù‡Ø§Ø¯ÙŠ ÙˆÙ„Ø§ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© ØŸ Ø´ÙƒÙˆÙ† ÙØ¹Ø§Ø¦Ù„ØªÙƒ Ùˆ...\n",
              "4   Ø­ÙŠØª Ø¹Ù†Ø¯Ù†Ø§ Ø¯ÙŠÙ…Ø§ Ù†ØªØ§ Ù„ÙˆÙ„ØŒ ØªØ¨Ø±Ø¹ Ø¨Ø§Ù„Ù…Ø§ÙƒØ³ Ø¯ÙŠØ§Ù„ Ø§Ù„Ø³Ø®...\n",
              "5   Ø§ØªØ¨Ø¹ÙˆØ§ Ù…Ø¹Ù†Ø§ ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ù‚Ø§ÙˆÙ„ Ø¹Ù…Ø±Ø§Ù† Ø³ÙŠÙ†Ùˆ Ø±Ø¦ÙŠØ³ ØªØ¹Ø§Ùˆ...\n",
              "6   Ù…Ø§ÙƒÙŠÙ† ØºÙŠØ± ÙÙˆØ±ÙÙŠ ØªØ¨Ø±Ø¹ Ø¨Ø§Ù„Ù„Ø§Ù…Ø­Ø¯ÙˆØ¯ØŒ ØªÙ…Ø²ÙƒØŒ ØªÙØ±Ø¬ Ùˆ ...\n",
              "7   Ø´Ø§Ø±Ùƒ Ù Ù…Ø¹ Ø£ÙˆØ±Ù†Ø¬ Ùˆ Ø¬Ù…Ø¹ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø¯ÙŠØ§Ù„Ùƒ Ø¨Ø§Ø´ ØªØ³Ø§Ù‡Ù… ...\n",
              "8   Ø£ÙˆØ±Ù†Ø¬ØŒ Ø±ÙŠØ²Ùˆ Ù„ÙŠ ÙÙŠÙ† Ù…Ø§ÙƒÙ†ØªÙŠ ÙŠØ¬Ø±ÙŠ Ø¨ÙŠÙƒ Ù„Ù„Ù‚Ø¯Ø§Ù… Ø§Ù„Ø±ÙŠ...\n",
              "9   ØºÙŠØ± Ø¹Ù†Ø¯ Ø£ÙˆØ±Ù†Ø¬ Ù‡Ø§Ø¯ Ø±Ù…Ø¶Ø§Ù† Ù…Ø§ÙƒÙŠÙ† ØºÙŠØ± Ù„ÙØ±Ø§Ø¬Ø© Ù‚Ø³ÙŠÙ…Ø©...\n",
              "10  Ø¨ÙØ¶Ù„ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø¯ÙŠØ§Ù„ÙƒÙ… Ø¬Ù…Ø¹Ù†Ø§ Ø§Ù„Ø£Ù†ØªØ±Ù†ÙŠØª Ù„ÙŠ ØªÙ… ØªÙˆØ²ÙŠ...\n",
              "11  Ø¨ÙØ¶Ù„ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø¯ÙŠØ§Ù„ÙƒÙ… Ø¬Ù…Ø¹Ù†Ø§ Ø§Ù„Ø£Ù†ØªØ±Ù†ÙŠØª Ù„ÙŠ ØªÙ… ØªÙˆØ²ÙŠ...\n",
              "12  Ø§ØªØ¨Ø¹ÙˆØ§ Ù…Ø¹Ù†Ø§ ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ù‚Ø§ÙˆÙ„Ø© Ø¨Ø§ÙŠØ§ ÙØ§Ø·Ù…Ø© ØµØ§Ø­Ø¨Ø© Ù…Ø´...\n",
              "13  Ø®Ø·ÙˆØ© Ø®ÙŠØ± Ù…Ø§Ø²Ø§Ù„ Ù…Ø³ØªÙ…Ø±Ø© Ù‡Ø§Ø¯ Ø±Ù…Ø¶Ø§Ù† Ø¹Ù„Ù‰ ÙƒÙ„ Ø®Ø·ÙˆØ© Ø¯Ø±...\n",
              "14  Ù‡Ø§Ø¯ Ø±Ù…Ø¶Ø§Ù† ØªÙØ±Ø¬ Ùˆ Ø²ÙŠÙŠÙŠÙŠØ¯ ØªÙØ±Ø¬ ÙÙŠ Ø¢Ø®Ø± Ø§Ù„Ø£ÙÙ„Ø§Ù… Ùˆ ...\n",
              "15  Ø­ÙŠØª Ø¹Ø§Ø±ÙÙŠÙ†ÙƒÙ… ÙƒØªØ¨ØºÙŠÙˆ ØªÙØ±Ø¬Ùˆ Ù…Ù† Ø§Ù„ØªÙŠØ±Ø§Ù†ØŒ Ø£ÙˆØ±Ù†Ø¬ Ø¬Ø§...\n",
              "16  Ø­ÙŠØª Ø¹Ù†Ø¯ Ø£ÙˆØ±Ù†Ø¬ Ù†ØªÙˆÙ…Ø§ Ø§Ù„Ù…Ø´Ø¬Ø¹ÙŠÙ† Ø±Ù‚Ù… Ø£ÙˆØ±Ù†Ø¬ Ø¬Ø§Øª Ø­ØªØ§...\n",
              "17  Ø§ØªØ¨Ø¹ÙˆØ§ Ù…Ø¹Ù†Ø§ ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ù‚Ø§ÙˆÙ„ Ù‡Ø´Ø§Ù… Ø¨Ù„Ø¹Ø²Ø±ÙŠ ØµØ§Ø­Ø¨ Ù…Ø´Ø±...\n",
              "18  Ø¨ØºÙŠØªÙˆ ÙØ±Ø­Ø© Ø±Ù…Ø¶Ø§Ù† ØªÙƒÙ…Ù„ Ùˆ ØªØ³ØªÙ…ØªØ¹ÙˆØ§ ÙÙƒÙ„ Ù†Ù‡Ø§Ø± ÙÙŠÙ‡ ...\n",
              "19  Ø§Ù„Ø®ÙŠØ± ØºÙŠØ± Ø¨Ø®Ø·ÙˆØ© ÙƒØ§ÙÙŠØŒ ÙƒÙ†ØªÙŠ Ø´ÙŠØ® ÙˆÙ„Ø§ ØµØ§Ø¨ÙŠØŒ Ø­ÙŠØª Øº..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-126364d2-ad92-491e-b397-fbe4568a022f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ads_clean</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ø­ØµØ±ÙŠØ§Ù‹ Ùˆ ØºÙŠØ± Ø¹Ù†Ø¯ Ø§ÙˆØ±Ù†Ø¬ØŒ Ø¹ÙŠØ´ Ù„ÙÙŠØ¨Ø± ÙØ¯Ø§Ø±Ùƒ ÙˆÙ†ØªØ§ Ù‡...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ØªØ¹Ø±ÙÙˆØ§ Ù…Ø¹Ù†Ø§ Ø¹Ù„Ù‰ Ø³Ø± Ø§Ù„Ø­Ø±ÙØ© Ù…Ø¹ ÙØ§Ø·Ù…Ø©ØŒ Ø¹Ù…Ø±Ø§Ù† Ùˆ Ù‡Ø´...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Ø¨ÙØ¶Ù„ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø¯ÙŠØ§Ù„ÙƒÙ… ÙˆØ²Ø¹Ù†Ø§ Ø§Ù„Ø§Ø£Ù†ØªØ±Ù†Øª Ø¹Ù„Ù‰ Ø¹Ø¯Ø© Ø¬Ù…...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Ø§Ù„Ø³Ø§Ø¹Ø© Ø¬Ø¯ÙŠØ¯Ø© Ù‡Ø§Ø¯ÙŠ ÙˆÙ„Ø§ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© ØŸ Ø´ÙƒÙˆÙ† ÙØ¹Ø§Ø¦Ù„ØªÙƒ Ùˆ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Ø­ÙŠØª Ø¹Ù†Ø¯Ù†Ø§ Ø¯ÙŠÙ…Ø§ Ù†ØªØ§ Ù„ÙˆÙ„ØŒ ØªØ¨Ø±Ø¹ Ø¨Ø§Ù„Ù…Ø§ÙƒØ³ Ø¯ÙŠØ§Ù„ Ø§Ù„Ø³Ø®...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Ø§ØªØ¨Ø¹ÙˆØ§ Ù…Ø¹Ù†Ø§ ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ù‚Ø§ÙˆÙ„ Ø¹Ù…Ø±Ø§Ù† Ø³ÙŠÙ†Ùˆ Ø±Ø¦ÙŠØ³ ØªØ¹Ø§Ùˆ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Ù…Ø§ÙƒÙŠÙ† ØºÙŠØ± ÙÙˆØ±ÙÙŠ ØªØ¨Ø±Ø¹ Ø¨Ø§Ù„Ù„Ø§Ù…Ø­Ø¯ÙˆØ¯ØŒ ØªÙ…Ø²ÙƒØŒ ØªÙØ±Ø¬ Ùˆ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Ø´Ø§Ø±Ùƒ Ù Ù…Ø¹ Ø£ÙˆØ±Ù†Ø¬ Ùˆ Ø¬Ù…Ø¹ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø¯ÙŠØ§Ù„Ùƒ Ø¨Ø§Ø´ ØªØ³Ø§Ù‡Ù… ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Ø£ÙˆØ±Ù†Ø¬ØŒ Ø±ÙŠØ²Ùˆ Ù„ÙŠ ÙÙŠÙ† Ù…Ø§ÙƒÙ†ØªÙŠ ÙŠØ¬Ø±ÙŠ Ø¨ÙŠÙƒ Ù„Ù„Ù‚Ø¯Ø§Ù… Ø§Ù„Ø±ÙŠ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>ØºÙŠØ± Ø¹Ù†Ø¯ Ø£ÙˆØ±Ù†Ø¬ Ù‡Ø§Ø¯ Ø±Ù…Ø¶Ø§Ù† Ù…Ø§ÙƒÙŠÙ† ØºÙŠØ± Ù„ÙØ±Ø§Ø¬Ø© Ù‚Ø³ÙŠÙ…Ø©...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Ø¨ÙØ¶Ù„ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø¯ÙŠØ§Ù„ÙƒÙ… Ø¬Ù…Ø¹Ù†Ø§ Ø§Ù„Ø£Ù†ØªØ±Ù†ÙŠØª Ù„ÙŠ ØªÙ… ØªÙˆØ²ÙŠ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Ø¨ÙØ¶Ù„ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø¯ÙŠØ§Ù„ÙƒÙ… Ø¬Ù…Ø¹Ù†Ø§ Ø§Ù„Ø£Ù†ØªØ±Ù†ÙŠØª Ù„ÙŠ ØªÙ… ØªÙˆØ²ÙŠ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Ø§ØªØ¨Ø¹ÙˆØ§ Ù…Ø¹Ù†Ø§ ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ù‚Ø§ÙˆÙ„Ø© Ø¨Ø§ÙŠØ§ ÙØ§Ø·Ù…Ø© ØµØ§Ø­Ø¨Ø© Ù…Ø´...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Ø®Ø·ÙˆØ© Ø®ÙŠØ± Ù…Ø§Ø²Ø§Ù„ Ù…Ø³ØªÙ…Ø±Ø© Ù‡Ø§Ø¯ Ø±Ù…Ø¶Ø§Ù† Ø¹Ù„Ù‰ ÙƒÙ„ Ø®Ø·ÙˆØ© Ø¯Ø±...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Ù‡Ø§Ø¯ Ø±Ù…Ø¶Ø§Ù† ØªÙØ±Ø¬ Ùˆ Ø²ÙŠÙŠÙŠÙŠØ¯ ØªÙØ±Ø¬ ÙÙŠ Ø¢Ø®Ø± Ø§Ù„Ø£ÙÙ„Ø§Ù… Ùˆ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Ø­ÙŠØª Ø¹Ø§Ø±ÙÙŠÙ†ÙƒÙ… ÙƒØªØ¨ØºÙŠÙˆ ØªÙØ±Ø¬Ùˆ Ù…Ù† Ø§Ù„ØªÙŠØ±Ø§Ù†ØŒ Ø£ÙˆØ±Ù†Ø¬ Ø¬Ø§...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Ø­ÙŠØª Ø¹Ù†Ø¯ Ø£ÙˆØ±Ù†Ø¬ Ù†ØªÙˆÙ…Ø§ Ø§Ù„Ù…Ø´Ø¬Ø¹ÙŠÙ† Ø±Ù‚Ù… Ø£ÙˆØ±Ù†Ø¬ Ø¬Ø§Øª Ø­ØªØ§...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Ø§ØªØ¨Ø¹ÙˆØ§ Ù…Ø¹Ù†Ø§ ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ù‚Ø§ÙˆÙ„ Ù‡Ø´Ø§Ù… Ø¨Ù„Ø¹Ø²Ø±ÙŠ ØµØ§Ø­Ø¨ Ù…Ø´Ø±...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Ø¨ØºÙŠØªÙˆ ÙØ±Ø­Ø© Ø±Ù…Ø¶Ø§Ù† ØªÙƒÙ…Ù„ Ùˆ ØªØ³ØªÙ…ØªØ¹ÙˆØ§ ÙÙƒÙ„ Ù†Ù‡Ø§Ø± ÙÙŠÙ‡ ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Ø§Ù„Ø®ÙŠØ± ØºÙŠØ± Ø¨Ø®Ø·ÙˆØ© ÙƒØ§ÙÙŠØŒ ÙƒÙ†ØªÙŠ Ø´ÙŠØ® ÙˆÙ„Ø§ ØµØ§Ø¨ÙŠØŒ Ø­ÙŠØª Øº...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-126364d2-ad92-491e-b397-fbe4568a022f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-126364d2-ad92-491e-b397-fbe4568a022f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-126364d2-ad92-491e-b397-fbe4568a022f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModelWithLMHead\n",
        "import pandas as pd\n",
        "\n",
        "# Load the pre-trained GPT-2 model and tokenizer for Arabic\n",
        "model_name = \"aubmindlab/aragpt2-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = TFAutoModelWithLMHead.from_pretrained(model_name)\n",
        "\n",
        "\n",
        "# Preprocess the data\n",
        "max_length = 512\n",
        "input_ids = []\n",
        "for text in data[\"ads_clean\"]:\n",
        "    encoded_text = tokenizer.encode(text, add_special_tokens=True, max_length=max_length)\n",
        "    input_ids.append(encoded_text)\n",
        "input_ids = tf.keras.preprocessing.sequence.pad_sequences(input_ids, maxlen=max_length, dtype=\"long\", value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "# Define the training parameters\n",
        "batch_size = 4\n",
        "learning_rate = 5e-5\n",
        "num_epochs = 6\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Define the training loop\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    for i in range(0, len(input_ids), batch_size):\n",
        "        batch = input_ids[i:i+batch_size]\n",
        "        with tf.GradientTape() as tape:\n",
        "            outputs = model(batch, return_dict=True)\n",
        "            loss_value = loss(batch[:, 1:], outputs.logits[:, :-1, :])\n",
        "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "        print(f\"Step {i//batch_size+1}/{len(input_ids)//batch_size+1}, Loss: {loss_value.numpy():.4f}\")\n",
        "    \n",
        "    # Generate text after each epoch\n",
        "    prompt = \"Ø­ÙŠØª Ø¹Ù†Ø¯ Ø£ÙˆØ±Ù†Ø¬ Ù†ØªÙˆÙ…Ø§\"\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"tf\")\n",
        "    generated = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        max_length=50,\n",
        "        num_beams=5,\n",
        "        no_repeat_ngram_size=2,\n",
        "        early_stopping=True,\n",
        "        temperature=1.0,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "    )\n",
        "    text = tokenizer.decode(generated[0], skip_special_tokens=True)\n",
        "    print(f\"Generated text: {text}\")\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained(\"arabic_gpt2\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUtlxgi7_ecg",
        "outputId": "ac0c6909-7028-4a51-ca62-2ec5f9cc1aad"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/modeling_tf_auto.py:649: FutureWarning: The class `TFAutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `TFAutoModelForCausalLM` for causal language models, `TFAutoModelForMaskedLM` for masked language models and `TFAutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n",
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at aubmindlab/aragpt2-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7f278001f640> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7f278001f640> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1/8, Loss: 0.5983\n",
            "Step 2/8, Loss: 0.5320\n",
            "Step 3/8, Loss: 0.4973\n",
            "Step 4/8, Loss: 0.3482\n",
            "Step 5/8, Loss: 0.4478\n",
            "Step 6/8, Loss: 0.4164\n",
            "Step 7/8, Loss: 0.2110\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 8/8, Loss: 0.4326\n",
            "Generated text: Ø­ÙŠØª Ø¹Ù†Ø¯ Ø£ÙˆØ±Ù†Ø¬ Ù†ØªÙˆÙ…Ø§ Ø¨ØºÙŠØªÙŠ Ù†Ø¯ÙŠØ±Ùˆ Ø¹Ù„Ù‰ Ù‡Ø§Ø¯ Ø§Ù„Ù‡Ø¶Ø±Ø©\n",
            "Epoch 2/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1/1, Loss: 3.3114\n",
            "Generated text: Ø­ÙŠØª Ø¹Ù†Ø¯ Ø£ÙˆØ±Ù†Ø¬ Ù†ØªÙˆÙ…Ø§ Ø­ØªØ§Ù„ Ø¹Ù„Ù‰ Ù‡Ø§Ø¯ Ø§Ù„Ù‡Ø¶Ø±Ø©.\n",
            "Epoch 3/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1/1, Loss: 1.3382\n",
            "Generated text: Ø­ÙŠØª Ø¹Ù†Ø¯ Ø£ÙˆØ±Ù†Ø¬ Ù†ØªÙˆÙ…Ø§ Ù„Ù‚Ø¯Ø§Ù…Ùˆ Ù†Ø¬ÙŠÙˆÙƒÙ… Ù…Ø¹Ù†Ø§ Ø¹Ù„Ù‰ Ø§Ù„ÙÙŠØ³Ø¨ÙˆÙƒ [Ø±Ø§Ø¨Ø·]\n",
            "Epoch 4/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1/1, Loss: 0.0636\n",
            "Generated text: Ø­ÙŠØª Ø¹Ù†Ø¯ Ø£ÙˆØ±Ù†Ø¬ Ù†ØªÙˆÙ…Ø§ ÙÙŠ\n",
            "Epoch 5/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1/1, Loss: 0.0084\n",
            "Generated text: Ø­ÙŠØª Ø¹Ù†Ø¯ Ø£ÙˆØ±Ù†Ø¬ Ù†ØªÙˆÙ…Ø§ ÙÙŠ\n",
            "Epoch 6/6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 1/1, Loss: 0.0004\n",
            "Generated text: Ø­ÙŠØª Ø¹Ù†Ø¯ Ø£ÙˆØ±Ù†Ø¬ Ù†ØªÙˆÙ…Ø§ ÙƒØªÙˆÙ…Ø§ Ø¥Ù„Ø¹Ø¨ÙˆØ§ Ø£ÙˆØ±Ø³ÙƒÙˆØ§ Ù…Ø¹Ù†Ø§ Ø¹Ù„Ù‰ Ø§Ù„ÙŠÙˆØªÙˆØ¨ Ùˆ ØºØ§Ø¯ÙŠ Ù†ØªÙˆØ§ØµÙ„ Ù…Ø¹ÙƒÙ… Ø¹Ù„Ù‰ Ø§Ù„ÙÙŠØ³Ø¨ÙˆÙƒ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import AutoTokenizer, TFAutoModelWithLMHead\n",
        "\n",
        "# Load the pre-trained GPT-2 model and tokenizer for Arabic\n",
        "model_name = \"aubmindlab/aragpt2-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = TFAutoModelWithLMHead.from_pretrained(model_name)\n",
        "\n",
        "# Tokenize the text\n",
        "input_ids = tokenizer.encode(text, return_tensors=\"tf\")\n",
        "\n",
        "# Define the training parameters\n",
        "batch_size = 4\n",
        "learning_rate = 5e-5\n",
        "num_epochs = 5\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "\n",
        "# Define the training loop\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    for i in range(0, len(input_ids), batch_size):\n",
        "        batch = input_ids[i:i+batch_size]\n",
        "        with tf.GradientTape() as tape:\n",
        "            outputs = model(batch, return_dict=True)\n",
        "            loss_value = loss(batch[:, 1:], outputs.logits[:, :-1, :])\n",
        "        grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "        optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "        print(f\"Step {i//batch_size+1}/{len(input_ids)//batch_size+1}, Loss: {loss_value.numpy():.4f}\")\n",
        "    \n",
        "    # Generate text after each epoch\n",
        "    prompt = \"Ø§ØªØ§ÙŠ\"\n",
        "    input_ids = tokenizer.encode(prompt, return_tensors=\"tf\")\n",
        "    generated = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        max_length=50,\n",
        "        num_beams=5,\n",
        "        no_repeat_ngram_size=2,\n",
        "        early_stopping=True,\n",
        "        temperature=1.0,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "    )\n",
        "    text = tokenizer.decode(generated[0], skip_special_tokens=True)\n",
        "    print(f\"Generated text: {text}\")\n",
        "\n",
        "# Save the model\n",
        "model.save_pretrained(\"arabic_gpt2\")\n"
      ],
      "metadata": {
        "id": "yf49cqunQu8Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "3c9d3966-0b9c-4245-d4e2-8a136ce90d9e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/modeling_tf_auto.py:649: FutureWarning: The class `TFAutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `TFAutoModelForCausalLM` for causal language models, `TFAutoModelForMaskedLM` for masked language models and `TFAutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n",
            "All model checkpoint layers were used when initializing TFGPT2LMHeadModel.\n",
            "\n",
            "All the layers of TFGPT2LMHeadModel were initialized from the model checkpoint at aubmindlab/aragpt2-base.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFGPT2LMHeadModel for predictions without further training.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-a97c0a29717a>\u001b[0m in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Load the text data from a file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mdata_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/path/to/data.txt\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/path/to/data.txt'"
          ]
        }
      ]
    }
  ]
}